import os
import sys

sys.path.append(r"D:\APP\CLIP-main")

import clip
import torch
import cv2
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from pycocotools.coco import COCO
import random
from tqdm import tqdm
import time  # æ–°å¢ï¼šç”¨äºè®¡ç®—è€—æ—¶

# ================= âš™ï¸ é…ç½®åŒºåŸŸ =================
TARGET_CATEGORY = 'cat'
TEXT_PROMPT = f"the {TARGET_CATEGORY}"
NUM_SAMPLES = 20
# æè¿°æ–‡ä»¶
ANN_PATH = r"dataset/refcoco/annotations_trainval2014/annotations/instances_train2014.json"
# æ•°æ®é›†
IMG_BASE_DIR = r"dataset/refcoco/train2014/train2014"
# è¾“å‡ºç›®å½•
SAVE_DIR = "output/clip_sam_image"
os.makedirs(SAVE_DIR, exist_ok=True)
DEVICE_ID = 0  # æŒ‡å®šGPUç¼–å·
# ===============================================

# --- è§£å†³matplotlibå­—ä½“è­¦å‘Šï¼ˆæ–°å¢ï¼‰---
plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'SimHei', 'Arial']  # å¢åŠ å­—ä½“ fallback
plt.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜
plt.rcParams['font.family'] = 'sans-serif'

# --- åˆå§‹åŒ–è®¾å¤‡ï¼ˆGPUæ¨¡å¼ï¼‰---
if torch.cuda.is_available():
    device = f"cuda:{DEVICE_ID}"
    torch.backends.cudnn.benchmark = True
    torch.cuda.set_device(DEVICE_ID)
    print(f"âœ… æ£€æµ‹åˆ°CUDAï¼Œä½¿ç”¨GPU {DEVICE_ID} è¿è¡Œ (torchç‰ˆæœ¬: {torch.__version__}, CUDA: {torch.cuda.is_available()})")
else:
    device = "cpu"
    print("âš ï¸ æœªæ£€æµ‹åˆ°CUDAï¼Œè‡ªåŠ¨é™çº§ä¸ºCPUæ¨¡å¼")

print(f"âš™ï¸ åˆå§‹åŒ–: å¯»æ‰¾ '{TEXT_PROMPT}' ({device}æ¨¡å¼)...")

# --- åŠ è½½æ¨¡å‹ ---
model_clip, preprocess = clip.load("ViT-B/32", device=device)
model_clip.eval()

from sam2.build_sam import build_sam2
from sam2.sam2_image_predictor import SAM2ImagePredictor

sam2_checkpoint = r"./checkpoints/sam2.1_hiera_base_plus.pt"
model_cfg = "configs/sam2.1/sam2.1_hiera_b+.yaml"
sam2_model = build_sam2(model_cfg, sam2_checkpoint, device=device)
mask_generator_predictor = SAM2ImagePredictor(sam2_model)


# --- å·¥å…·å‡½æ•° ---
def calculate_box_iou(box1, box2):
    x1, y1, w1, h1 = box1
    x2, y2, w2, h2 = box2
    b1_x1, b1_y1, b1_x2, b1_y2 = x1, y1, x1 + w1, y1 + h1
    b2_x1, b2_y1, b2_x2, b2_y2 = x2, y2, x2 + w2, y2 + h2
    inter_x1 = max(b1_x1, b2_x1)
    inter_y1 = max(b1_y1, b2_y1)
    inter_x2 = min(b1_x2, b2_x2)
    inter_y2 = min(b1_y2, b2_y2)
    if inter_x1 >= inter_x2 or inter_y1 >= inter_y2: return 0.0
    inter_area = (inter_x2 - inter_x1) * (inter_y2 - inter_y1)
    b1_area = (b1_x2 - b1_x1) * (b1_y2 - b1_y1)
    b2_area = (b2_x2 - b2_x1) * (b2_y2 - b2_y1)
    return inter_area / (b1_area + b2_area - inter_area)


def calculate_mask_iou(mask1, mask2):
    inter = np.logical_and(mask1, mask2).sum()
    union = np.logical_or(mask1, mask2).sum()
    return inter / union if union > 0 else 0.0


def get_clip_heatmap_center(image, text):
    if image.size[0] == 0 or image.size[1] == 0:
        print("âš ï¸ å›¾ç‰‡å°ºå¯¸å¼‚å¸¸ï¼Œè¿”å›é»˜è®¤ä¸­å¿ƒç‚¹")
        return np.array([[image.size[0] // 2, image.size[1] // 2]])

    h, w = image.size[1], image.size[0]
    small_img = image.resize((224, 224))
    grid_h, grid_w = 7, 7
    patch_h, patch_w = 224 // grid_h, 224 // grid_w
    patches = []

    for i in range(grid_h):
        for j in range(grid_w):
            patch = small_img.crop((j * patch_w, i * patch_h, (j + 1) * patch_w, (i + 1) * patch_h))
            patches.append(preprocess(patch))

    image_input = torch.stack(patches).to(device, dtype=torch.float32)
    text_token = clip.tokenize([text]).to(device)

    with torch.no_grad():
        img_feats = model_clip.encode_image(image_input)
        txt_feats = model_clip.encode_text(text_token)
        img_feats /= img_feats.norm(dim=-1, keepdim=True)
        txt_feats /= txt_feats.norm(dim=-1, keepdim=True)
        sim = (img_feats @ txt_feats.T).squeeze()

    sim_np = sim.cpu().numpy()
    sim_np = np.nan_to_num(sim_np, nan=0.0, posinf=0.0, neginf=0.0)
    heatmap = sim_np.reshape(grid_h, grid_w).astype(np.float32)

    if heatmap.size == 0 or w == 0 or h == 0:
        print("âš ï¸ çƒ­åŠ›å›¾å°ºå¯¸å¼‚å¸¸ï¼Œè¿”å›é»˜è®¤ä¸­å¿ƒç‚¹")
        return np.array([[w // 2, h // 2]])

    heatmap = cv2.resize(heatmap, (w, h), interpolation=cv2.INTER_LINEAR)
    heatmap_blur = cv2.GaussianBlur(heatmap, (15, 15), 0)
    (_, _, _, maxLoc) = cv2.minMaxLoc(heatmap_blur)

    if maxLoc[0] < 0 or maxLoc[1] < 0 or maxLoc[0] >= w or maxLoc[1] >= h:
        maxLoc = (w // 2, h // 2)

    return np.array([maxLoc])


# --- ä¸»å¾ªç¯ï¼ˆé‡ç‚¹ä¼˜åŒ–tqdmï¼‰---
def run_evaluation():
    coco = COCO(ANN_PATH)
    cat_ids = coco.getCatIds(catNms=[TARGET_CATEGORY])
    if not cat_ids:
        print(f"âŒ COCO ä¸­æ²¡æœ‰ '{TARGET_CATEGORY}' è¿™ä¸ªç±»åˆ«")
        return
    img_ids = coco.getImgIds(catIds=cat_ids)
    sample_ids = random.sample(img_ids, min(NUM_SAMPLES, len(img_ids)))
    total_samples = len(sample_ids)
    print(f"ğŸš€ å¼€å§‹è¯„ä¼° {total_samples} å¼ å›¾ç‰‡ (ç›®æ ‡ç±»åˆ«: {TARGET_CATEGORY})...")

    mask_ious = []
    box_ious = []
    success_mask_count = 0
    success_box_count = 0
    failed_count = 0  # æ–°å¢ï¼šç»Ÿè®¡å¤±è´¥æ•°
    start_time = time.time()  # æ–°å¢ï¼šè®°å½•å¼€å§‹æ—¶é—´

    # --- ä¼˜åŒ–tqdmè¿›åº¦æ¡é…ç½® ---
    pbar = tqdm(
        sample_ids,
        total=total_samples,
        desc=f"ğŸ“Š è¯„ä¼°è¿›åº¦ [{TARGET_CATEGORY}]",  # è‡ªå®šä¹‰æè¿°
        bar_format="{l_bar}{bar:20}{r_bar}",  # è¿›åº¦æ¡å®½åº¦å›ºå®š20å­—ç¬¦
        colour="green",  # è¿›åº¦æ¡é¢œè‰²ï¼ˆgreen/red/blue/yellowï¼‰
        ncols=100,  # è¿›åº¦æ¡æ€»å®½åº¦
        unit="img",  # å•ä½åç§°
        dynamic_ncols=False,  # å›ºå®šå®½åº¦ï¼Œé¿å…é—ªçƒ
        leave=True  # å®Œæˆåä¿ç•™è¿›åº¦æ¡
    )

    for idx, img_id in enumerate(pbar):
        img_info = coco.loadImgs(img_id)[0]
        img_path = os.path.join(IMG_BASE_DIR, img_info['file_name'])

        if not os.path.exists(img_path):
            failed_count += 1
            # æ›´æ–°è¿›åº¦æ¡æè¿°ï¼ˆå®æ—¶æ˜¾ç¤ºå…³é”®æŒ‡æ ‡ï¼‰
            pbar.set_postfix({
                "mIoU": f"{np.mean(mask_ious):.4f}" if mask_ious else "0.0000",
                "æˆåŠŸç‡": f"{success_mask_count / (idx + 1):.2%}" if (idx + 1) > 0 else "0.00%",
                "å¤±è´¥æ•°": failed_count,
                "è€—æ—¶": f"{time.time() - start_time:.1f}s"
            })
            pbar.update(1)
            continue

        try:
            image = Image.open(img_path).convert("RGB")
            if image.size[0] < 10 or image.size[1] < 10:
                failed_count += 1
                pbar.set_postfix({
                    "mIoU": f"{np.mean(mask_ious):.4f}" if mask_ious else "0.0000",
                    "æˆåŠŸç‡": f"{success_mask_count / (idx + 1):.2%}" if (idx + 1) > 0 else "0.00%",
                    "å¤±è´¥æ•°": failed_count,
                    "è€—æ—¶": f"{time.time() - start_time:.1f}s"
                })
                pbar.update(1)
                continue

            img_np = np.array(image)
            input_point = get_clip_heatmap_center(image, TEXT_PROMPT)
            mask_generator_predictor.set_image(img_np)
            masks, scores, _ = mask_generator_predictor.predict(
                point_coords=input_point,
                point_labels=np.array([1]),
                multimask_output=False
            )
            pred_mask = masks[0]

            y_ind, x_ind = np.where(pred_mask > 0)
            if len(y_ind) > 0:
                pred_bbox = [x_ind.min(), y_ind.min(), x_ind.max() - x_ind.min(), y_ind.max() - y_ind.min()]
            else:
                pred_bbox = [0, 0, 0, 0]

            ann_ids = coco.getAnnIds(imgIds=img_id, catIds=cat_ids)
            anns = coco.loadAnns(ann_ids)
            best_m_iou = 0.0
            best_b_iou = 0.0

            for ann in anns:
                gt_mask = coco.annToMask(ann)
                m = calculate_mask_iou(pred_mask, gt_mask)
                b = calculate_box_iou(pred_bbox, ann['bbox'])
                if m > best_m_iou: best_m_iou = m
                if b > best_b_iou: best_b_iou = b

            if best_m_iou >= 0 and best_b_iou >= 0:
                mask_ious.append(best_m_iou)
                box_ious.append(best_b_iou)
                if best_m_iou > 0.5: success_mask_count += 1
                if best_b_iou > 0.5: success_box_count += 1

            # å¯è§†åŒ–ï¼ˆæ›¿æ¢emojiä¸ºæ–‡å­—ï¼Œè§£å†³å­—ä½“è­¦å‘Šï¼‰
            plt.figure(figsize=(12, 6))
            plt.subplot(1, 2, 1)
            plt.imshow(img_np)
            color = np.array([1.0, 0.0, 0.0, 0.6])
            h_mask, w_mask = pred_mask.shape[-2:]
            mask_vis = pred_mask.reshape(h_mask, w_mask, 1) * color.reshape(1, 1, -1)
            plt.imshow(mask_vis)
            plt.scatter(input_point[0][0], input_point[0][1], c='yellow', marker='*', s=200, edgecolors='black')
            # æ ¸å¿ƒä¿®æ”¹ï¼šæ›¿æ¢emojiä¸ºæ–‡å­—ï¼ˆHit/Missï¼‰
            is_hit = "Hit" if best_m_iou > 0.5 else "Miss"
            title_text = f"Prompt: \"{TEXT_PROMPT}\"\nMask IoU: {best_m_iou:.2f} | {is_hit}"
            plt.title(title_text, fontsize=12, fontweight='bold', color='blue')
            plt.axis('off')

            plt.subplot(1, 2, 2)
            ov2 = img_np.copy()
            for ann in anns:
                gm = coco.annToMask(ann)
                ov2[gm > 0] = [0, 255, 0]
            plt.imshow(cv2.addWeighted(img_np, 0.6, ov2, 0.4, 0))
            plt.title(f"Ground Truth ({TARGET_CATEGORY})", fontsize=12)
            plt.axis('off')

            plt.savefig(f"{SAVE_DIR}/eval_{idx}_{TARGET_CATEGORY}.jpg", bbox_inches='tight')
            plt.close()

            torch.cuda.empty_cache()

            # --- å®æ—¶æ›´æ–°è¿›åº¦æ¡åç¼€ï¼ˆæ ¸å¿ƒä¼˜åŒ–ï¼‰---
            current_progress = idx + 1
            avg_miou = np.mean(mask_ious) if mask_ious else 0.0
            success_rate = success_mask_count / current_progress if current_progress > 0 else 0.0
            elapsed_time = time.time() - start_time
            eta = (elapsed_time / current_progress) * (
                        total_samples - current_progress) if current_progress > 0 else 0  # é¢„è®¡å‰©ä½™æ—¶é—´

            pbar.set_postfix({
                "mIoU": f"{avg_miou:.4f}",
                "æˆåŠŸç‡": f"{success_rate:.2%}",
                "å¤±è´¥æ•°": failed_count,
                "è€—æ—¶": f"{elapsed_time:.1f}s",
                "å‰©ä½™": f"{eta:.1f}s"  # æ–°å¢ï¼šé¢„è®¡å‰©ä½™æ—¶é—´
            })

        except Exception as e:
            failed_count += 1
            print(f"\nâš ï¸ å¤„ç†å›¾ç‰‡ {img_id} æ—¶å‡ºé”™: {str(e)}")
            torch.cuda.empty_cache()
            # å‡ºé”™æ—¶ä¹Ÿæ›´æ–°è¿›åº¦æ¡
            current_progress = idx + 1
            avg_miou = np.mean(mask_ious) if mask_ious else 0.0
            success_rate = success_mask_count / current_progress if current_progress > 0 else 0.0
            elapsed_time = time.time() - start_time
            eta = (elapsed_time / current_progress) * (total_samples - current_progress) if current_progress > 0 else 0

            pbar.set_postfix({
                "mIoU": f"{avg_miou:.4f}",
                "æˆåŠŸç‡": f"{success_rate:.2%}",
                "å¤±è´¥æ•°": failed_count,
                "è€—æ—¶": f"{elapsed_time:.1f}s",
                "å‰©ä½™": f"{eta:.1f}s"
            })

    pbar.close()

    # è®¡ç®—æœ€ç»ˆæŒ‡æ ‡
    total_time = time.time() - start_time
    m_iou = np.mean(mask_ious) if mask_ious else 0.0
    b_iou = np.mean(box_ious) if box_ious else 0.0
    success_rate = success_mask_count / total_samples if total_samples > 0 else 0.0
    avg_time_per_img = total_time / total_samples if total_samples > 0 else 0.0

    # æ‰“å°ç¾åŒ–åçš„ç»“æœ
    print("\n" + "=" * 60)
    print(f"ğŸ“Š æœ€ç»ˆè¯„ä¼°ç»“æœ (ç›®æ ‡: '{TEXT_PROMPT}', è®¾å¤‡: {device})")
    print("=" * 60)
    print(f"ğŸ“ˆ åˆ†å‰²ç²¾åº¦ (mIoU)       : {m_iou:.4f}")
    print(f"ğŸ“ æ¡†ç²¾åº¦ (IoU@0.5)      : {b_iou:.4f}")
    print(f"âœ… æˆåŠŸç‡ (Mask IoU>0.5) : {success_rate:.2%} ({success_mask_count}/{total_samples})")
    print(f"âŒ å¤±è´¥æ•°                : {failed_count}")
    print(f"â±ï¸  æ€»è€—æ—¶               : {total_time:.2f}ç§’")
    print(f"âš¡ å•å›¾å¹³å‡è€—æ—¶           : {avg_time_per_img:.2f}ç§’")
    print("=" * 60)
    print(f"ğŸ“ ç»“æœå·²ä¿å­˜è‡³: {os.path.abspath(SAVE_DIR)}")


if __name__ == "__main__":
    run_evaluation()